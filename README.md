# RAG-Instruct-Chatbot: An Advanced NLP Project for Question Answering

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Xt273_sH-Epx2pI6ypQH66oqBkbZAcNg)

This repository presents an end-to-end Natural Language Processing (NLP) project focused on building and evaluating a robust Retrieval-Augmented Generation (RAG) system. The project leverages a synthetic Q&A dataset derived from Wikipedia to develop a powerful question-answering chatbot capable of retrieving relevant information and generating concise, accurate responses.

## ‚ú® Key Features

*   **Comprehensive Data Analysis:** In-depth exploration of the RAG-Instruct dataset, including length distributions, vocabulary statistics, PCA for dimensionality reduction, K-Means clustering, and Latent Dirichlet Allocation (LDA) for topic modeling.
*   **Hybrid Search Engine:** Implementation and evaluation of a multi-stage retrieval system combining:
    *   **Keyword Search:** BM25 and DirichletLM using PyTerrier.
    *   **Dense Retrieval:** Alibaba GTE and Sentence-Transformer models (MiniLM-L6) with FAISS and HNSWLIB for Approximate Nearest Neighbor (ANN) search.
    *   **Re-ranking:** LambdaMART for learning-to-rank, and Cross-Encoder (BGE-reranker) for fine-grained relevance scoring.
*   **Custom Word Embeddings:** Training and intrinsic/extrinsic evaluation of Word2Vec and FastText models on the project's corpus.
*   **Large Language Model (LLM) Fine-tuning:** Fine-tuning the `Meta-Llama-3.1-8B` model using Unsloth and LoRA adapters on the RAG-Instruct Q&A pairs for enhanced domain-specific generation.
*   **LLM-powered Chatbot:** Development of a conversational chatbot using LangChain, integrating the developed retrieval system with a Google Gemini 1.5 Flash LLM for response generation.
*   **Robust Evaluation Frameworks:**
    *   **Information Retrieval (IR) Metrics:** Precision@K, Average Precision (AP), and Mean Average Precision (MAP) for search engine performance.
    *   **Natural Language Generation (NLG) Metrics:** BLEU, ROUGE, METEOR, and Perplexity for evaluating the fine-tuned model's generation quality.
    *   **LLM-as-a-Judge:** A novel approach using DeepSeek LLM to qualitatively assess chatbot responses across various criteria (fluency, coherence, engagingness, etc.).
    *   **Heuristic-based Ground Truth:** An alternative method to identify relevant documents for evaluation, complementing LLM-judged ground truth.

## üõ†Ô∏è Technical Stack

*   **Programming Language:** Python 3.x
*   **Machine Learning/NLP Frameworks:**
    *   `transformers`, `sentence-transformers`, `unsloth` (for LLM operations)
    *   `gensim` (Word2Vec, FastText, LDA)
    *   `pyterrier` (Information Retrieval)
    *   `faiss-gpu`, `hnswlib` (Vector Databases / ANN Search)
    *   `scikit-learn` (Clustering, PCA, TF-IDF)
    *   `lightgbm` (LambdaMART reranker)
    *   `langchain`, `langchain-google-genai` (Chatbot orchestration)
*   **Data Handling:** `pandas`, `datasets` (Hugging Face Datasets)
*   **Visualization:** `matplotlib`, `seaborn`, `pyLDAvis`, `umap-learn`
*   **Core Libraries:** `nltk`, `spacy`, `numpy`, `tqdm`, `warnings`
*   **LLMs Used:**
    *   `Meta-Llama-3.1-8B` (Fine-tuned)
    *   `Gemini 1.5 Flash` (Chatbot core)
    *   `DeepSeek v3 Base` (LLM-as-a-Judge for chatbot evaluation)
    *   `Alibaba-NLP/gte-large-en-v1.5` (Dense Retrieval)
    *   `sentence-transformers/multi-qa-MiniLM-L6-cos-v1` (Dense Retrieval)
    *   `cross-encoder/ms-marco-MiniLM-L-6-v2` (Cross-encoder reranking)

## üìä Dataset Overview

The project utilizes the [FreedomIntelligence/RAG-Instruct](https://huggingface.co/datasets/FreedomIntelligence/RAG-Instruct) dataset, comprising ~40,000 Q&A pairs synthesized from Wikipedia. Each entry includes:
*   `question`: Natural-language query generated by GPT-4o.
*   `answer`: One-paragraph response from GPT-4o referencing seed passages.
*   `documents`: Exactly 10 passages (seed D\* + 8‚Äì9 distractors D‚Åª), shuffled.

## üöÄ Getting Started

To run this project, you'll need Python 3.8+ and access to Google Colab (recommended due to GPU requirements for LLMs and embeddings) or a machine with CUDA support.

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/RAG-Instruct-Chatbot.git
cd RAG-Instruct-Chatbot
```

### 2. Install Dependencies

The `nlp_final_delivery.py` script includes all necessary `pip install` commands at the beginning. If running locally, it's recommended to install them in a virtual environment:

```bash
pip install -r requirements.txt # (assuming you generate this file)
# Or manually install from the script:
# pip install "numpy<2.0" gensim nltk umap-learn scikit-learn matplotlib tqdm pandas pyLDAvis unsloth rouge-score transformers torch evaluate sacrebleu bert-score python-terrier google-genai lightgbm rank_bm25 sentence-transformers accelerate faiss-gpu xformers hnswlib whoosh pytrec_eval fsspec langchain langchain-google-genai langchain-openai langchain-community
```

### 3. Google Drive Setup (for cached models and data)

Many parts of the project involve saving large models (e.g., Word2Vec, FastText, embedding caches) and evaluation results to Google Drive to avoid re-computation.
The script expects a specific folder structure: `/content/drive/MyDrive/NLP_project/`.
Ensure you mount your Google Drive in your Colab environment:

```python
from google.colab import drive
drive.mount('/content/drive')
```
And create the `NLP_project` folder inside `MyDrive`.

### 4. API Keys

*   **Google Gemini API Key:** Required for the chatbot and LLM-as-a-Judge evaluations. Set it as an environment variable or directly in the code (as shown in the `chatbot` section):
    `os.environ["GOOGLE_API_KEY"] = "YOUR_GOOGLE_GEMINI_API_KEY"`
*   **OpenRouter API Key:** Used for the DeepSeek LLM-as-a-Judge. Similarly, set it as an environment variable:
    `os.environ["OPENROUTER_API_KEY"] = "YOUR_OPENROUTER_API_KEY"`

### 5. Running the Project

The entire project is structured as a single Python script (`nlp_final_delivery.py`) designed to be executed sequentially, ideally within a Google Colab notebook. You can run cells step-by-step to understand each component, or execute the entire script.

**Note:** Re-embedding large datasets (e.g., Alibaba GTE embeddings) can be time-consuming. The script includes logic to load pre-computed embeddings from Google Drive if they exist, controlled by a `should_embed_data` flag in the `CONFIG CELL`. Set this to `False` after the first run.

## üìà Results and Insights

### Data Analysis
The dataset primarily consists of short questions (avg. 20 words) and longer answers (avg. 91 words). PCA and KMeans clustering identified a dominant cluster, suggesting the dataset covers a few core topics with variations. LDA revealed 15 distinct topics, with terms like "model", "language", "data", "system", and "protein" being prominent.

### Search Engine
The project implemented a hybrid retrieval strategy. Initial keyword search (BM25, DirichletLM) was combined with dense retrieval (Alibaba GTE, MiniLM-L6) using FAISS/HNSWLIB. A LambdaMART reranker significantly improved the ranking of relevant documents, demonstrating the power of supervised learning for information retrieval.

### Word Embeddings
Custom Word2Vec and FastText models were trained on the corpus. Both performed well on intrinsic (word analogy, similarity) and extrinsic (retrieval-at-k) benchmarks, confirming their utility for capturing semantic relationships specific to the dataset's domain. FastText showed better handling of OOV words.

### Retrieval-Augmented Generation (RAG)
The combined retrieval pipeline (dense + reranking) was effective in fetching relevant documents. The adaptive thresholding mechanism in the `combined_search` function dynamically selects the most relevant documents based on their fused scores, ensuring high-quality context for the LLM.

### LLM Fine-tuning
The `Meta-Llama-3.1-8B` model was successfully fine-tuned using Unsloth's LoRA implementation. The training loss curve showed convergence. Evaluation using standard NLG metrics (BLEU, ROUGE, METEOR, Perplexity) demonstrated a demonstrable improvement in the fine-tuned model's ability to generate relevant and coherent answers, closely aligning with the original dataset's answers.

### Chatbot and LLM-as-a-Judge Evaluation
The LangChain-powered chatbot, leveraging the hybrid retrieval system and Gemini 1.5 Flash, provided engaging and informative responses. A cutting-edge "LLM-as-a-Judge" framework (using DeepSeek LLM) was implemented for qualitative evaluation. This unbiased assessment revealed high scores across criteria like `fluency`, `making_sense`, `avoiding_repetition`, and `listening`, indicating a performant and human-like conversational agent.

## üì∫ Video Demo

A video demonstration of the project and its functionalities is available here:
[Project Demo Video](https://polimi365-my.sharepoint.com/personal/10968409_polimi_it/_layouts/15/stream.aspx?id=%2Fpersonal%2F10968409%5Fpolimi%5Fit%2FDocuments%2Fnlp%2Dproj%2Dragnroll%201%2Emov&nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJTdHJlYW1XZWJBcHAiLCJyZWZlcnJhbFZpZXciOiJTaGFyZURpYWxvZytMaW5rIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXcifX0%3D&nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJTdHJlYW1XZWJBcHAiLCJyZWZlcnJhbFZpZXciOiJTaGFyZURpYWxvZytMaW5rIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXcifX0=&ga=1)


## üìÑ License

This project is licensed under the MIT License - see the `LICENSE` file for details.

---
